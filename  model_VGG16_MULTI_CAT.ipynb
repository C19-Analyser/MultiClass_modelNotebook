{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification multi etiquette par exctraction de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des modules necessaire :\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 800 images d'entrainement de patient atelectasis.\n",
      "Il y a 1106 images d'entrainement de patient sain.\n",
      "Il y a 800 images d'entrainement de patient effusion.\n",
      "Il y a 1380 images d'entrainement de patient emphyseme.\n",
      "Il y a 1348 images d'entrainement de patient infltration.\n",
      "Il y a 1000 images d'entrainement de patient pneumonie.\n",
      "Il y a 102 images de validation de patient atelectasis.\n",
      "Il y a 930 images de validation de patient non-covid.\n",
      "Il y a 133 images de validation de patient effusion.\n",
      "Il y a 193 images de validation de patient emphyseme.\n",
      "Il y a 193 images de validation de patient infltration.\n",
      "Il y a 333 images de validation de patient pneumonie.\n",
      "Il y a 102 images test de patient atelectasis.\n",
      "Il y a 872 images test de patient non-covid.\n",
      "Il y a 133 images test de patient effusion.\n",
      "Il y a 193 images test de patient emphyseme.\n",
      "Il y a 387 images test de patient infltration.\n",
      "Il y a 333 images test de patient pneumonie.\n"
     ]
    }
   ],
   "source": [
    "# On declare les chemins vers les donnees :\n",
    "\n",
    "Image = 'Data'\n",
    "        \n",
    "train_data_dir = 'Data/TRAIN'\n",
    "validation_data_dir = 'Data/VALIDATION'\n",
    "test_data_dir = 'Data/TEST'\n",
    "\n",
    "# Dimmension et path :\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "#ImageTRAINCOVID = os.listdir(Image + '/TRAIN/COVID')\n",
    "ImageTRAINATELECTASIS = os.listdir(Image + '/TRAIN/ATELECTASIS')\n",
    "ImageTRAINNORMAL = os.listdir(Image + '/TRAIN/NORMAL')\n",
    "ImageTRAINEFFUSION = os.listdir(Image + '/TRAIN/EFFUSION')\n",
    "ImageTRAINEMPHYSEMA = os.listdir(Image + '/TRAIN/EMPHYSEMA')\n",
    "ImageTRAININFILTRATION = os.listdir(Image + '/TRAIN/INFILTRATION')\n",
    "ImageTRAINPNEUMONIE = os.listdir(Image + '/TRAIN/PNEUMONIE')\n",
    "\n",
    "#ImageVALIDATIONCOVID = os.listdir(Image + '/VALIDATION/COVID')\n",
    "ImageVALIDATIONATELECTASIS = os.listdir(Image + '/VALIDATION/ATELECTASIS')\n",
    "ImageVALIDATIONNORMAL = os.listdir(Image + '/VALIDATION/NORMAL')\n",
    "ImageVALIDATIONEFFUSION = os.listdir(Image + '/VALIDATION/EFFUSION')\n",
    "ImageVALIDATIONEMPHYSEMA = os.listdir(Image + '/VALIDATION/EMPHYSEMA')\n",
    "ImageVALIDATIONINFILTRATION = os.listdir(Image + '/VALIDATION/INFILTRATION')\n",
    "ImageVALIDATIONPNEUMONIE = os.listdir(Image + '/VALIDATION/PNEUMONIE')\n",
    "\n",
    "#ImageTESTCOVID = os.listdir(Image + '/TEST/COVID')\n",
    "ImageTESTATELECTASIS = os.listdir(Image + '/TEST/ATELECTASIS')\n",
    "ImageTESTNORMAL = os.listdir(Image + '/TEST/NORMAL')\n",
    "ImageTESTEFFUSION = os.listdir(Image + '/TEST/EFFUSION')\n",
    "ImageTESTEMPHYSEMA = os.listdir(Image + '/TEST/EMPHYSEMA')\n",
    "ImageTESTINFILTRATION = os.listdir(Image + '/TEST/INFILTRATION')\n",
    "ImageTESTPNEUMONIE = os.listdir(Image + '/TEST/PNEUMONIE')\n",
    "\n",
    "#print('Il y a ' + str(len(ImageTRAINCOVID)) + ' images d\\'entrainement de patient covid.') \n",
    "print('Il y a ' + str(len(ImageTRAINATELECTASIS)) + ' images d\\'entrainement de patient atelectasis.') \n",
    "print('Il y a ' + str(len(ImageTRAINNORMAL)) + ' images d\\'entrainement de patient sain.') \n",
    "print('Il y a ' + str(len(ImageTRAINEFFUSION)) + ' images d\\'entrainement de patient effusion.') \n",
    "print('Il y a ' + str(len(ImageTRAINEMPHYSEMA)) + ' images d\\'entrainement de patient emphyseme.') \n",
    "print('Il y a ' + str(len(ImageTRAININFILTRATION)) + ' images d\\'entrainement de patient infltration.')\n",
    "print('Il y a ' + str(len(ImageTRAINPNEUMONIE)) + ' images d\\'entrainement de patient pneumonie.')\n",
    "\n",
    "#print('Il y a ' + str(len(ImageVALIDATIONCOVID)) + ' images de validation de patient covid.') \n",
    "print('Il y a ' + str(len(ImageVALIDATIONATELECTASIS)) + ' images de validation de patient atelectasis.') \n",
    "print('Il y a ' + str(len(ImageVALIDATIONNORMAL)) + ' images de validation de patient non-covid.') \n",
    "print('Il y a ' + str(len(ImageVALIDATIONEFFUSION)) + ' images de validation de patient effusion.') \n",
    "print('Il y a ' + str(len(ImageVALIDATIONEMPHYSEMA)) + ' images de validation de patient emphyseme.') \n",
    "print('Il y a ' + str(len(ImageVALIDATIONINFILTRATION)) + ' images de validation de patient infltration.')\n",
    "print('Il y a ' + str(len(ImageVALIDATIONPNEUMONIE)) + ' images de validation de patient pneumonie.')\n",
    "\n",
    "#print('Il y a ' + str(len(ImageTESTCOVID)) + ' images test de patient covid.') \n",
    "print('Il y a ' + str(len(ImageTESTATELECTASIS)) + ' images test de patient atelectasis.') \n",
    "print('Il y a ' + str(len(ImageTESTNORMAL)) + ' images test de patient non-covid.')\n",
    "print('Il y a ' + str(len(ImageTESTEFFUSION)) + ' images test de patient effusion.') \n",
    "print('Il y a ' + str(len(ImageTESTEMPHYSEMA)) + ' images test de patient emphyseme.') \n",
    "print('Il y a ' + str(len(ImageTESTINFILTRATION)) + ' images test de patient infltration.')\n",
    "print('Il y a ' + str(len(ImageTESTPNEUMONIE)) + ' images test de patient pneumonie.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7816 images belonging to 7 classes.\n",
      "Found 2102 images belonging to 7 classes.\n",
      "Found 2260 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing :\n",
    "\n",
    "# On rescale les images :\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# On definit la batch size :\n",
    "\n",
    "batch_size = 32 \n",
    "\n",
    "# On prepare les tableaux de donnees depuis les images :\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size)\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de DENSE121 sans la partie fully-connected avec le reseau convolutif :\n",
    "\n",
    "model_vgg = applications.VGG16(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilse le model VGG16 pour extraire les features de nos images \n",
    "# (on fait recupere la sortie du reseau convolutionnel) :\n",
    "train_features = model_vgg.predict_generator(train_generator, 7816 // batch_size)\n",
    "\n",
    "validation_features = model_vgg.predict_generator(validation_generator, 2102 // batch_size)\n",
    "\n",
    "# L'opération étant longue on enregistre les features obtenus :\n",
    "np.save(open('models/trainFeatures_VGG16_AllDataExtend.npy', 'wb'), train_features) # ecriture en binaire necessaire\n",
    "np.save(open('models/validationFeatures_VGG16_AllDataExtend.npy', 'wb'), validation_features) # Idem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si l'operation à deja été effectuer on charge les features :\n",
    "\n",
    "train_features = np.load(open('models/trainFeatures_VGG16_AllData.npy', 'rb'))\n",
    "validation_features = np.load(open('models/validationFeatures_VGG16_AllData.npy', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array([0] * 800 + [1] * 1386 + [2] * 800 + [3] * 1380 + [4] * 1348 + [5] * 1102 + [6] * 992 )\n",
    "\n",
    "validation_labels = np.array([0] * 102 + [1] * 219 + [2] * 128 + [3] * 192 + [4] * 192 + [5] * 928 + [6] * 319 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                1605696   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 1,606,151\n",
      "Trainable params: 1,606,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_top = Sequential()\n",
    "model_top.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model_top.add(Dense(64, activation='relu'))\n",
    "model_top.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# On compile :\n",
    "model_top.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# On affiche :\n",
    "model_top.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "batch_size = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input arrays should have the same number of samples as target arrays. Found 3520 input samples and 7808 target samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5d2f5bcee5d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         validation_data=(validation_features, validation_labels))\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2532\u001b[0m       \u001b[0;31m# Check that all arrays have the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2534\u001b[0;31m         \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_array_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2536\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_array_lengths\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    675\u001b[0m                      \u001b[0;34m'the same number of samples as target arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                      \u001b[0;34m'Found '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input samples '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                      'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[1;32m    678\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     raise ValueError('All sample_weight arrays should have '\n",
      "\u001b[0;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 3520 input samples and 7808 target samples."
     ]
    }
   ],
   "source": [
    "history = model_top.fit(train_features, train_labels,\n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_top.save('models/VGG16_Full_MAXG_224_224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "history2 = model_top.fit(train_features, train_labels,\n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "history3 = model_top.fit(train_features, train_labels,\n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_top.save('models/VGG16_Full_MAX2G_224_224')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
